y <- rnorm(x)
plot(x,y)
hist(x, y, col="black")
hist(x, y)
hist(x, y)
help.start()
hist(x)
hist(x,y)
boxplot(x)
hist(x)
rm(y)
y
1/x
x <- c(10.4, 5.6, 3.1, 6.4, 21.7)
1/x
temp <- x>13
temp
task1 <- x>3 && x<7
task1
x <- c(10.4, 5.6, 3.1, 6.4, 21.7)
task1 <- x>3 && x<7
task1
task1 <- (x>3 && x<7)
task1
task1 <- x>3 | x<7
task1
task1 <- x>3 & x<7
task1
paste(c("A","B"), 1:10, sep=" ")
paste(c("A","B"), 1:10, sep="")
z <- c(4:8,NA)
is.na(z)
x <- c(-5:-1, NA, NA, 1:3)
y <- x[!is.na(x)]
y
library(dplyr)
library(dplyr)
install.packages("dplyr")
installed.packages("dplyr")
library(dplyr)
library(dplyr)
library(dplyr)
library(dplyr)
library(dplyr)
library(dplyr)
titanicData <-read.csv("titanic.csv", header=T, na.strings=c(""),stringsAsFactors = T)
titanicData <-read.csv("\Users\Yogiraj\Documents\National College of Ireland\R Lab\Lap Exercises\titanic.csv", header=T, na.strings=c(""),stringsAsFactors = T)
titanicData <-read.csv("/Users/Yogiraj\Documents/National College of Ireland/R Lab/Lap Exercises/titanic.csv", header=T, na.strings=c(""),stringsAsFactors = T)
titanicData <-read.csv("/Users/Yogiraj/Documents/National College of Ireland/R Lab/Lap Exercises/titanic.csv", header=T, na.strings=c(""),stringsAsFactors = T)
titanicData$Survived = as.factor((titanicData$Survived))
titanicData$Pclass <- as.factor(titanicData$Pclass)
String(titanicData)
titanicData.df
embarkedNAs <- titanicData %>%
filter(PassengerId ==  62 | PassengerId  == 830)
print(embarkedNAs[,c(3,10,4)])
ImputedAgeMean <- titanicData$Age
ImputedAgeMean[is.na(ImputedAgeMean)] <- mean(ImputedAgeMean, na.rm = TRUE)
ImputedAgeMean
ImputedAgeMean[is.na(ImputedAgeMean)]
ImputedAgeMean <- titanicData$Age
ImputedAgeMean[is.na(ImputedAgeMean)] <- mean(ImputedAgeMean, na.rm = TRUE)
ImputedAgeMean[is.na(ImputedAgeMean)]
ImputedAgeMean
par(mfrow=c(1,2))
hist(titanicData$Age)
hist(ImputedAgeMean)
ImputedAgeMedian <- titanicData$Age
ImputedAgeMedian[is.na(ImputedAgeMedian)] <- mean(ImputedAgeMedian, na.rm = TRUE)
par(mfrow=c(1,2))
hist(titanicData$Age)
hist(ImputedAgeMedian)
library(MASS)
library(ISLR2)
install package("ISLR2")
install packages("ISLR2")
install.packages("ISLR2")
library(ISLR2)
library(ISLR2)
head(Boston)
lm.fit <- lm(medv ∼ lstat , data = Boston)
attach (Boston)
attach (Boston)
attach (Boston)
lm.fit <- lm(medv ∼ lstat)
lm.fit
summary(lm.fit)
names(lm.fit)
coef(lm.fit)
confint(lm.fit)
predict(lm.fit, data.frame(lstat = c(5,10,15)), interval = "confidence")
predict(lm.fit, data.frame(lstat = c(5,10,15)), interval = "prediction")
plot(lstat, medv)
abline(lm.fit)
abline(lm.fit, lwd=3)
abline(lm.fit, lwd=3, col="red")
plot(lstat, medv, col = "red")
plot(lstat, medv, pch = 20)
plot(lstat, medv. pch = "+")
plot(lstat, medv. pch = "+")
plot(lstat, medv, pch = "+")
plot(1:20, 1:20, pch = 1:20)
par(mfrow = c(2,2))
par(mfrow = c(2,2))
plot(lm.fit)
plot(predict(lm.fit), residuals(lm.fit))
plot(predict(lm.fit), rstudent(lm.fit))
plot(predict(lm.fit)), rstudent(lm.fit))
Plot(predict(lm.fit), rstudent(lm.fit))
plot(1:20, 1:20, pch = 1:20)
library(stats)
#install.packages('caTools')
library(caTools)
library(Amelia)
library(dplyr)
setwd("~/National College of Ireland/Machine Learning Project/Final Datasets/Jupyter FIles/Bank Customer Churn Analysis")
BCustDF <- read.csv(file="Bank_CUstomer_Churn_Data.csv")
head(BCustDF)
#Print the structure of the dataframe
print(str(BCustDF))
table(BCustDF$Exited)
#Checking if there are any null values
sapply(BCustDF,function(x) sum(is.na(x)))
summary(BCustDF) #No NULL values here!
#install.packages("visdat")
library(visdat)
#Check Missing Values
vis_miss(BCustDF)
#Dropping unwanted columns
BCustDF$RowNumber <- NULL
BCustDF$Surname <- NULL
summary(BCustDF)
head(BCustDF)
#Converting features into factors
BCustDF$CustomerId <- as.factor(BCustDF$CustomerId)
BCustDF$CreditScore <- as.factor(BCustDF$CreditScore)
BCustDF$Location <- as.factor(BCustDF$Location)
BCustDF$Gender <- as.factor(BCustDF$Gender)
BCustDF$Age <- as.factor(BCustDF$Age)
BCustDF$Tenure <- as.factor(BCustDF$Tenure)
BCustDF$Balance <- as.factor(BCustDF$Balance)
BCustDF$NumOfProducts <- as.factor(BCustDF$NumOfProducts)
BCustDF$HasCrCard <- as.factor(BCustDF$HasCrCard)
BCustDF$IsActiveMember<- as.factor(BCustDF$IsActiveMember)
BCustDF$EstimatedSalary <- as.factor(BCustDF$EstimatedSalary)
BCustDF$Exited <- as.factor(BCustDF$Exited)
#Checking dataframe structure again after conversion
str(BCustDF)
library(caTools)
split = sample.split(BCustDF$Exited, SplitRatio = 0.8)
training_set = subset(BCustDF, split == TRUE)
test_set = subset(BCustDF, split == FALSE)
library(randomForest)
library(randomForest)
#drops <- c("reviews_per_month")
#df = listings[ , !(names(listings) %in% drops)]
library(caTools)
set.seed(1000)
split = sample.split(BCustDF1$Exited, SplitRatio = 0.8)
training_set = subset(BCustDF1, split == TRUE)
test_set = subset(BCustDF1, split == FALSE)
BCustDF1 <- read.csv(file="Bank_CUstomer_Churn_Data.csv")
head(BCustDF1)
summary(BCustDF1)
str(BCustDF1)
sapply(BCustDF1,function(x) sum(is.na(x)))
BCustDF1$RowNumber <- NULL
BCustDF1$Surname <- NULL
summary(BCustDF1)
head(BCustDF1)
#Converting into Factors
BCustDF1$Exited <- as.factor(BCustDF1$Exited)
library(randomForest)
#drops <- c("reviews_per_month")
#df = listings[ , !(names(listings) %in% drops)]
library(caTools)
set.seed(1000)
split = sample.split(BCustDF1$Exited, SplitRatio = 0.8)
training_set = subset(BCustDF1, split == TRUE)
test_set = subset(BCustDF1, split == FALSE)
rf <- randomForest(formula = Exited ~ .,data = training_set,mtry=3, ntree=500, importance=TRUE, do.trace=100)
rf
print(rf)
plot(rf)
dt_predic = predict(rf,test_set,type="class")
conf_mat <- confusionMatrix(as.factor(dt_predic),as.factor(test_set$Exited))
library(caret)
conf_mat <- confusionMatrix(as.factor(dt_predic),as.factor(test_set$Exited))
conf_mat
model <- "Random Forest Model"
accuracy <- conf_mat$overall[1]
accuracy_table <- data.frame(model,accuracy)
accuracy_table
# Model Performance Matrix
data.frame(R2 - R2(dt_predic,test_set$Exited), RMSE - RMSE(dt_predic,test_set$Exited), MAE - MAE(dt_predic,test_set$Exited))
class(dt_predic)
Exited
class(test_set$Exited)
# Model Performance Matrix
data.frame(R2 - R2(dt_predic,as.numeric(test_set$Exited)), RMSE - RMSE(dt_predic,as.numeric(test_set$Exited)), MAE - MAE(dt_predic,as.numeric(test_set$Exited)))
# Model Performance Matrix
data.frame(R2 - R2(as.numeric(dt_predic),as.numeric(test_set$Exited)), RMSE - RMSE(as.numeric(dt_predic),as.numeric(test_set$Exited)), MAE - MAE(as.numeric(dt_predic),as.numeric(test_set$Exited)))
rf <- randomForest(formula = Exited ~ .,data = training_set,mtry=best.m, ntree=500, importance=TRUE, do.trace=100)
rf <- randomForest(formula = Exited ~ .,data = training_set,mtry=4, ntree=500, importance=TRUE, do.trace=100)
plot(rf)
# Model Performance Matrix
data.frame(R2 = R2(as.numeric(dt_predic),as.numeric(test_set$Exited)), RMSE = RMSE(as.numeric(dt_predic),as.numeric(test_set$Exited)), MAE = MAE(as.numeric(dt_predic),as.numeric(test_set$Exited)))
class(dt_predic)
class(test_set$Exited)
library(caret)
conf_mat <- confusionMatrix(as.factor(dt_predic),as.factor(test_set$Exited))
conf_mat
# Model Performance Matrix
data.frame(R2 = R2(as.numeric(dt_predic),as.numeric(test_set$Exited)), RMSE = RMSE(as.numeric(dt_predic),as.numeric(test_set$Exited)), MAE = MAE(as.numeric(dt_predic),as.numeric(test_set$Exited)))
importance(rf)
#Plotting ROC Curve
#install.packages(("ROCR"))
library(ROCR)
pred_nb <- as.numeric(pred_nb)
dt_predic <- as.numeric(dt_predic)
predt <- prediction(pred_nb,test_set$Attrition)
predt <- prediction(dt_predic,test_set$Attrition)
dt_predic
levels(dt_predic) <- list("0" = "1", "1" = "2")
predt <- prediction(dt_predic,test_set$Attrition)
dt_predic <- as.numeric(dt_predic)
predt <- prediction(dt_predic,test_set$Attrition)
dt_predic
predt <- prediction(dt_predic,test_set$Exited)
ROCperflr <- performance(predt,measure="tpr",x.measure = "fpr")
plot(ROCperflr, colorsize = TRUE, print.cutoffs.at=seq(0,1,by=0.2),text.adj=c(-0.2,1.7))
BCustDF1 <- read.csv(file="Bank_CUstomer_Churn_Data.csv")
head(BCustDF1)
summary(BCustDF1)
str(BCustDF1)
sapply(BCustDF1,function(x) sum(is.na(x)))
BCustDF1$RowNumber <- NULL
BCustDF1$Surname <- NULL
summary(BCustDF1)
head(BCustDF1)
#Converting into Factors
BCustDF1$Exited <- as.factor(BCustDF1$Exited)
BCustDF1$CreditScore <- as.numeric(BCustDF1$CreditScore)
BCustDF1$Location <- as.factor(BCustDF1$Location)
BCustDF1$Gender <- as.factor(BCustDF1$Gender)
BCustDF1$Age <- as.numeric(BCustDF1$Age)
BCustDF1$Tenure <- as.numeric(BCustDF1$Tenure)
BCustDF1$Balance <- as.numeric(BCustDF1$Balance)
BCustDF1$NumOfProducts <- as.numeric(BCustDF1$NumOfProducts)
BCustDF1$HasCrCard <- as.factor(BCustDF1$HasCrCard)
BCustDF1$IsActiveMember<- as.factor(BCustDF1$IsActiveMember)
library(randomForest)
#drops <- c("reviews_per_month")
#df = listings[ , !(names(listings) %in% drops)]
library(caTools)
set.seed(1000)
split = sample.split(BCustDF1$Exited, SplitRatio = 0.8)
training_set = subset(BCustDF1, split == TRUE)
test_set = subset(BCustDF1, split == FALSE)
rf <- randomForest(formula = Exited ~ .,data = training_set,mtry=4, ntree=500, importance=TRUE, do.trace=100)
rf
print(rf)
importance(rf)
plot(rf)
dt_predic = predict(rf,test_set,type="class")
# Model Performance Matrix
data.frame(R2 = R2(as.numeric(dt_predic),as.numeric(test_set$Exited)), RMSE = RMSE(as.numeric(dt_predic),as.numeric(test_set$Exited)), MAE = MAE(as.numeric(dt_predic),as.numeric(test_set$Exited)))
class(dt_predic)
class(test_set$Exited)
#Plotting ROC Curve
#install.packages(("ROCR"))
library(ROCR)
dt_predic <- as.numeric(dt_predic)
predt <- prediction(dt_predic,test_set$Exited)
ROCperflr <- performance(predt,measure="tpr",x.measure = "fpr")
plot(ROCperflr, colorsize = TRUE, print.cutoffs.at=seq(0,1,by=0.2),text.adj=c(-0.2,1.7))
library(caret)
conf_mat <- confusionMatrix(as.factor(dt_predic),as.factor(test_set$Exited))
dt_predic
dt_predic<- as.factor(dt_predic)
conf_mat <- confusionMatrix(as.factor(dt_predic),as.factor(test_set$Exited))
levels(pred_nb) <- list("0" = "1", "1" = "2")
levels(dt_predic) <- list("0" = "1", "1" = "2")
conf_mat <- confusionMatrix(as.factor(dt_predic),as.factor(test_set$Exited))
conf_mat
model <- "Random Forest Model"
accuracy <- conf_mat$overall[1]
accuracy_table <- data.frame(model,accuracy)
accuracy_table
library(stats)
#install.packages('caTools')
library(caTools)
library(Amelia)
library(dplyr)
setwd("~/National College of Ireland/Machine Learning Project/Final Datasets/Jupyter FIles/Bank Customer Churn Analysis")
BCustDF <- read.csv(file="Bank_CUstomer_Churn_Data.csv")
head(BCustDF)
#Print the structure of the dataframe
print(str(BCustDF))
table(BCustDF$Exited)
#Checking if there are any null values
sapply(BCustDF,function(x) sum(is.na(x)))
summary(BCustDF) #No NULL values here!
#install.packages("visdat")
library(visdat)
#Check Missing Values
vis_miss(BCustDF)
#Dropping unwanted columns
BCustDF$RowNumber <- NULL
BCustDF$Surname <- NULL
summary(BCustDF)
head(BCustDF)
#Converting features into factors
BCustDF$CustomerId <- as.factor(BCustDF$CustomerId)
BCustDF$CreditScore <- as.factor(BCustDF$CreditScore)
BCustDF$Location <- as.factor(BCustDF$Location)
BCustDF$Gender <- as.factor(BCustDF$Gender)
BCustDF$Age <- as.factor(BCustDF$Age)
BCustDF$Tenure <- as.factor(BCustDF$Tenure)
BCustDF$Balance <- as.factor(BCustDF$Balance)
BCustDF$NumOfProducts <- as.factor(BCustDF$NumOfProducts)
BCustDF$HasCrCard <- as.factor(BCustDF$HasCrCard)
BCustDF$IsActiveMember<- as.factor(BCustDF$IsActiveMember)
BCustDF$EstimatedSalary <- as.factor(BCustDF$EstimatedSalary)
BCustDF$Exited <- as.factor(BCustDF$Exited)
#Checking dataframe structure again after conversion
str(BCustDF)
library(caTools)
#Splitting data into Training and Test
set.seed(1000)
split = sample.split(BCustDF$Exited, SplitRatio = 0.8)
training_set = subset(BCustDF, split == TRUE)
test_set = subset(BCustDF, split == FALSE)
View(training_set)
View(test_set)
#Applying Decision Tree Model
library(rpart)
library(rpart.plot)
rpart.plot(decision_tree_model,type=5)
decision_tree_model<-rpart(Exited~.,data=training_set,method="class",control=rpart.control(cp=0.03))
rpart.plot(decision_tree_model,type=5)
printcp(decision_tree_model)
plotcp(decision_tree_model)
prp(decision_tree_model)
dt_predic_class = predict(decision_tree_model,test_set,type="class")
conf_mat <- confusionMatrix(as.factor(dt_predic_class),as.factor(test_set$Exited))
conf_mat
model <- "Decision Tree Model"
accuracy <- conf_mat$overall[1]
accuracy_table <- data.frame(model,accuracy)
accuracy_table
decision_tree_model<-rpart(Exited~CreditScore + Location + Gender,data=training_set,method="class",control=rpart.control(cp=0.03))
rpart.plot(decision_tree_model,type=5)
printcp(decision_tree_model)
plotcp(decision_tree_model)
prp(decision_tree_model)
decision_tree_model<-rpart(Exited~CreditScore + Location + Gender + Age + Tenure + Balance + NumOfProducts + HasCrCard + IsActiveMember + EstimatedSalary,data=training_set,method="class",control=rpart.control(cp=0.03))
rpart.plot(decision_tree_model,type=5)
printcp(decision_tree_model)
plotcp(decision_tree_model)
prp(decision_tree_model)
dt_predic_class = predict(decision_tree_model,test_set,type="class")
conf_mat <- confusionMatrix(as.factor(dt_predic_class),as.factor(test_set$Exited))
conf_mat
model <- "Decision Tree Model"
accuracy <- conf_mat$overall[1]
accuracy_table <- data.frame(model,accuracy)
accuracy_table
BCustDF1 <- read.csv(file="Bank_CUstomer_Churn_Data.csv")
data.frame(R2 = R2(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), RMSE = RMSE((as.numeric(dt_predic_class),as.numeric(test_set$Exited), MAE = MAe(as.numeric((dt_predic_class)),as.numeric((test_set$Exited)))))
data.frame(R2 = R2(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), RMSE = RMSE((as.numeric(dt_predic_class),as.numeric(test_set$Exited)), MAE = MAe(as.numeric(dt_predic_class),as.numeric(test_set$Exited))))
conf_mat <- confusionMatrix(as.factor(dt_predic_class),as.factor(test_set$Exited))
data.frame(R2 = R2(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), RMSE = RMSE(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), MAE = MAe(as.numeric(dt_predic_class),as.numeric(test_set$Exited)))
data.frame(R2 = R2(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), RMSE = RMSE(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), MAE = MAE(as.numeric(dt_predic_class),as.numeric(test_set$Exited)))
conf_mat
prp(decision_tree_model)
decision_tree_model<-rpart(Exited~CreditScore + Location + Gender + Age + Tenure + Balance + NumOfProducts + HasCrCard + IsActiveMember + EstimatedSalary,data=training_set,method="class",control=rpart.control(cp=0.03),minbucket = 25)
rpart.plot(decision_tree_model,type=5)
printcp(decision_tree_model)
plotcp(decision_tree_model)
prp(decision_tree_model)
plotcp(decision_tree_model)
dtree.prune<- prune(decision_tree_model, cp=0.0004)
dtree.prune
rpart.plot(melb.prune,type = 5,extra=101)
rpart.plot(dtree.prune,type = 5,extra=101)
plotcp(dtree.prune)
dt_predic_class = predict(dtree.prune,test_set,type="class")
data.frame(R2 = R2(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), RMSE = RMSE(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), MAE = MAE(as.numeric(dt_predic_class),as.numeric(test_set$Exited)))
conf_mat <- confusionMatrix(as.factor(dt_predic_class),as.factor(test_set$Exited))
conf_mat
model <- "Decision Tree Model"
accuracy <- conf_mat$overall[1]
accuracy_table <- data.frame(model,accuracy)
accuracy_table
#Applying Decision Tree Model
library(rpart)
library(rpart.plot)
decision_tree_model<-rpart(Exited~CreditScore + Location + Gender + Age + Tenure + Balance + NumOfProducts + HasCrCard + IsActiveMember + EstimatedSalary,data=training_set,method="class",control=rpart.control(cp=0.03),minbucket = 25)
rpart.plot(decision_tree_model,type=5)
printcp(decision_tree_model)
plotcp(decision_tree_model)
prp(decision_tree_model)
dtree.prune<- prune(decision_tree_model, cp=0.0001)
dtree.prune
rpart.plot(dtree.prune,type = 5,extra=101)
plotcp(dtree.prune)
#Applying Decision Tree Model
library(rpart)
library(rpart.plot)
decision_tree_model<-rpart(Exited~CreditScore + Location + Gender + Age + Tenure + Balance + NumOfProducts + HasCrCard + IsActiveMember + EstimatedSalary,data=training_set,method="class",control=rpart.control(cp=0.0001),minbucket = 25)
rpart.plot(decision_tree_model,type=5)
printcp(decision_tree_model)
plotcp(decision_tree_model)
prp(decision_tree_model)
dtree.prune<- prune(decision_tree_model, cp=0.0004)
dtree.prune
rpart.plot(dtree.prune,type = 5,extra=101)
plotcp(dtree.prune)
decision_tree_model<-rpart(Exited~CreditScore + Location + Gender + Age + Tenure + Balance + NumOfProducts + HasCrCard + IsActiveMember + EstimatedSalary,data=training_set,method="class",cp=0.0001,minbucket = 25)
rpart.plot(decision_tree_model,type=5)
printcp(decision_tree_model)
plotcp(decision_tree_model)
boxplot(TelCust_new$CreditScore,ylab = "Credit Score")
boxplot(BCustDF$CreditScore,ylab = "Credit Score")
boxplot(BCustDF$Location,ylab = "Job Involvement")
boxplot(BCustDF$Gender,ylab = "Job Level")
boxplot(BCustDF$Age, ylab = "StockOptionLevel")
boxplot(BCustDF$Tenure, ylab = "Total Working Years")
boxplot(BCustDF$Balance, ylab = "Years At Company")
boxplot(BCustDF$NumOfProducts, ylab = "Gender")
boxplot(BCustDF$HasCrCard, ylab = "Job Involvement")
boxplot(BCustDF$IsActiveMember, ylab = "Job Level")
boxplot(BCustDF$EstimatedSalary, ylab = "WorkLifeBalance")
boxplot(BCustDF$CreditScore,ylab = "Credit Score")
boxplot(IBMDF1_new$YearsAtCompany, ylab = "Years At Company")
boxplot(BCustDF$YearsAtCompany, ylab = "Years At Company")
boxplot(BCustDF$YearsAtCompany, ylab = "Years At Company")
IBMDF1_new = subset(IBMDF1_new, as.numeric(Age)<47 & as.numeric(NumOfProducts)<3.9)
IBMDF1_new = subset(BCustDF, as.numeric(Age)<47 & as.numeric(NumOfProducts)<3.9)
BCustDF_new = subset(BCustDF, as.numeric(Age)<47 & as.numeric(NumOfProducts)<3.9)
str(BCustDF_new)
#Check to confirm if outliers are removed
boxplot(BCustDF_new$Age,ylab = "Age")
boxplot(BCustDF_new$JobInvolvement,ylab = "Job Involvement")
boxplot(BCustDF_new$JobLevel,ylab = "Job Level")
boxplot(BCustDF$CreditScore,ylab = "Credit Score")
boxplot(BCustDF$Location,ylab = "Location")
boxplot(BCustDF$Gender,ylab = "Gender")
boxplot(BCustDF$Age, ylab = "Age")
BCustDF = subset(BCustDF, as.numeric(Age)<43 & as.numeric(NumOfProducts)<3.9)
str(BCustDF)
boxplot(BCustDF$CreditScore,ylab = "Credit Score")
boxplot(BCustDF$Location,ylab = "Location")
boxplot(BCustDF$Gender,ylab = "Gender")
boxplot(BCustDF$Age, ylab = "Age")
boxplot(BCustDF$Tenure, ylab = "Tenure")
boxplot(BCustDF$Balance, ylab = "Balance")
boxplot(BCustDF$NumOfProducts, ylab = "Number of Products")
boxplot(BCustDF$HasCrCard, ylab = "Has Credit Card")
boxplot(BCustDF$IsActiveMember, ylab = "Ia Active Member")
boxplot(BCustDF$EstimatedSalary, ylab = "Estimated Salary")
#Converting features into factors
BCustDF$CustomerId <- as.numeric(BCustDF$CustomerId)
BCustDF$CreditScore <- as.numeric(BCustDF$CreditScore)
BCustDF$Location <- as.factor(BCustDF$Location)
BCustDF$Gender <- as.factor(BCustDF$Gender)
BCustDF$Age <- as.numeric(BCustDF$Age)
BCustDF$Tenure <- as.numercr(BCustDF$Tenure)
BCustDF$Balance <- as.numeric(BCustDF$Balance)
BCustDF$Tenure <- as.numerir(BCustDF$Tenure)
BCustDF$Tenure <- as.numeric(BCustDF$Tenure)
BCustDF$NumOfProducts <- as.numeric(BCustDF$NumOfProducts)
BCustDF$HasCrCard <- as.numeric(BCustDF$HasCrCard)
BCustDF$IsActiveMember<- as.numeric(BCustDF$IsActiveMember)
BCustDF$EstimatedSalary <- as.numeric(BCustDF$EstimatedSalary)
library(caTools)
#Splitting data into Training and Test
set.seed(1000)
split = sample.split(BCustDF$Exited, SplitRatio = 0.8)
training_set = subset(BCustDF, split == TRUE)
test_set = subset(BCustDF, split == FALSE)
View(training_set)
View(test_set)
#Applying Decision Tree Model
library(rpart)
library(rpart.plot)
decision_tree_model<-rpart(Exited~CreditScore + Location + Gender + Age + Tenure + Balance + NumOfProducts + HasCrCard + IsActiveMember + EstimatedSalary,data=training_set,method="class",cp=0.0001,minbucket = 25)
rpart.plot(decision_tree_model,type=5)
printcp(decision_tree_model)
plotcp(decision_tree_model)
prp(decision_tree_model)
dtree.prune<- prune(decision_tree_model, cp=0.0004)
dtree.prune
rpart.plot(dtree.prune,type = 5,extra=101)
plotcp(dtree.prune)
dt_predic_class = predict(dtree.prune,test_set,type="class")
data.frame(R2 = R2(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), RMSE = RMSE(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), MAE = MAE(as.numeric(dt_predic_class),as.numeric(test_set$Exited)))
conf_mat <- confusionMatrix(as.factor(dt_predic_class),as.factor(test_set$Exited))
conf_mat
model <- "Decision Tree Model"
accuracy <- conf_mat$overall[1]
accuracy_table <- data.frame(model,accuracy)
accuracy_table
library(ROCR)
dt_predic <- as.numeric(dt_predic)
predt <- prediction(dt_predic,test_set$Exited)
dt_predic_class <- as.numeric(dt_predic_class)
predt <- prediction(dt_predic_class,test_set$Exited)
ROCperflr <- performance(predt,measure="tpr",x.measure = "fpr")
plot(ROCperflr, colorsize = TRUE, print.cutoffs.at=seq(0,1,by=0.2),text.adj=c(-0.2,1.7))
data.frame(R2 = R2(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), RMSE = RMSE(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), MAE = MAE(as.numeric(dt_predic_class),as.numeric(test_set$Exited)))
