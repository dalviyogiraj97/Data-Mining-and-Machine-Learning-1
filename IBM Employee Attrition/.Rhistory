facet_grid(~EVENT_LABEL) +
scale_y_continuous() +
scale_fill_manual(values = c("blue","purple")) +
theme(legend.position = "none", plot.title = element_text(hjust = 0.5)) +
ggtitle("Event Label - Legit/Fraud") +
labs(x = "Gender")
TelCust_new$EmployeeCount <- NULL
TelCust_new$EmployeeNumber <- NULL
TelCust_new$StandardHours <- NULL
TelCust_new$Over18 <- NULL
TelCust_new$Application.ID <- NULL
TelCust_new$Employee.Source <- NULL
TelCust_new$email_domain <- NULL
TelCust_new$phoneModel <-NULL
TelCust_new$billing_postal <- NULL
TelCust_new$billing_state <- NULL
TelCust_new$partner <- NULL
TelCust_new$PhoneService <- NULL
TelCust_new$MultipleLines <- NULL
TelCust_new$contract_code <- NULL
TelCust_new$currency_code <- NULL
TelCust_new$mobileHotspot <- NULL
TelCust_new$device_protection <- NULL
TelCust_new$paymentMethod <- NULL
TelCust_new$wifiCallingText <- NULL
TelCust_new$OnlineBackup <- NULL
TelCust_new$customer_reg_date <- NULL
TelCust_new$billing_city <- NULL
TelCust_new$networkSpeed <- NULL
TelCust_new$paperlessBilling <- NULL
TelCust_new$mailingcode <- NULL
TelCust_new$EVENT_TIMESTAMP <- NULL
TelCust_new$billing_address <- NULL
#Removing Columns
#TelCust_new$latePayments<- NULL
str(TelCust_new)
summary(TelCust_new)
TelCust_new$EVENT_LABEL <- ifelse(TelCust_new$EVENT_LABEL == "fraud",1,0)
# Check for any correlated variables
library(corrplot)
cor <- cor(TelCust_new[sapply(TelCust_new,is.numeric)])
corrplot(cor)
cor(cor)
TelCust_new$gender <- as.factor(TelCust_new$gender)
TelCust_new$EVENT_LABEL <- as.factor(TelCust_new$EVENT_LABEL)
TelCust_new$monthly_minutes <- as.factor(TelCust_new$monthly_minutes)
TelCust_new$customerServiceCalls <- as.numeric(TelCust_new$customerServiceCalls)
TelCust_new$streaming_minutes <- as.numeric(TelCust_new$streaming_minutes)
TelCust_new$TotalBilled <- as.numeric(TelCust_new$TotalBilled)
TelCust_new$PrevBalance <- as.numeric(TelCust_new$PrevBalance)
TelCust_new$latePayments <- as.factor(TelCust_new$latePayments)
TelCust_new$ip_address_asn <- as.factor(TelCust_new$ip_address_asn)
TelCust_new$phone_area_code <- as.factor(TelCust_new$phone_area_code)
str(TelCust_new)
#Kernel SVM Model
library(caTools)
y_pred_svm <- as.integer((y_pred_svm))
y_pred_svm<-ifelse(y_pred_svm> 0.5,1,0)
set.seed(1000)
split = sample.split(TelCust_new$EVENT_LABEL, SplitRatio = 0.7)
training_set = subset(TelCust_new, split == TRUE)
test_set = subset(TelCust_new, split == FALSE)
View(training_set)
View(test_set)
#install.packages('e1071')
library(e1071)
#install.packages("kernlab")
library(kernlab)
classifier_svm = svm(formula = EVENT_LABEL ~ gender + monthly_minutes + PrevBalance + latePayments + TotalBilled +  customerServiceCalls + phone_area_code,
data = training_set,
type = 'C-classification',
kernel = 'polynomial')
# Predicting the Test set results
y_pred_svm = predict(classifier_svm, newdata = test_set)
p_class_svm <- factor(y_pred_svm, levels = levels(test_set[["EVENT_LABEL"]]))
# Making the Confusion Matrix
conf_mat <- confusionMatrix(as.factor(y_pred_svm),as.factor(test_set$EVENT_LABEL))
conf_mat
model <- "SVM Model"
accuracy <- conf_mat$overall[1]
accuracy_table <- data.frame(model,accuracy)
accuracy_table
library(stats)
#install.packages('caTools')
library(caTools)
library(Amelia)
library(dplyr)
#Setting working directory in R
setwd("~/National College of Ireland/Machine Learning Project/Final Datasets/DMML_CA1/Bank Customer Churn Analysis")
#Read the Telecom dataset input file
BCustDF <- read.csv(file="Bank_CUstomer_Churn_Data.csv")
head(BCustDF)
#Print the structure of the dataframe
print(str(BCustDF))
table(BCustDF$Exited)
#Checking if there are any null values
sapply(BCustDF,function(x) sum(is.na(x)))
summary(BCustDF) #No NULL values here!
#install.packages("visdat")
library(visdat)
#Check Missing Values
vis_miss(BCustDF)
#Dropping unwanted columns
BCustDF$RowNumber <- NULL
BCustDF$Surname <- NULL
summary(BCustDF)
head(BCustDF)
#Need to remove Outliers
boxplot(BCustDF$CreditScore,ylab = "Credit Score")
boxplot(BCustDF$Age, ylab = "Age")
boxplot(BCustDF$Tenure, ylab = "Tenure")
boxplot(BCustDF$Balance, ylab = "Balance")
boxplot(BCustDF$NumOfProducts, ylab = "Number of Products")
boxplot(BCustDF$HasCrCard, ylab = "Has Credit Card")
boxplot(BCustDF$IsActiveMember, ylab = "Ia Active Member")
boxplot(BCustDF$EstimatedSalary, ylab = "Estimated Salary")
#Apply COnditions to Remove Outliers
library(dplyr)
BCustDF = subset(BCustDF, as.numeric(Age)<43 & as.numeric(NumOfProducts)<3.9)
str(BCustDF)
#Check to confirm if outliers are removed
boxplot(BCustDF$CreditScore,ylab = "Credit Score")
boxplot(BCustDF$Age, ylab = "Age")
boxplot(BCustDF$Tenure, ylab = "Tenure")
boxplot(BCustDF$Balance, ylab = "Balance")
boxplot(BCustDF$NumOfProducts, ylab = "Number of Products")
boxplot(BCustDF$HasCrCard, ylab = "Has Credit Card")
boxplot(BCustDF$IsActiveMember, ylab = "Ia Active Member")
boxplot(BCustDF$EstimatedSalary, ylab = "Estimated Salary")
#Converting features into factors
BCustDF$CustomerId <- as.numeric(BCustDF$CustomerId)
BCustDF$CreditScore <- as.numeric(BCustDF$CreditScore)
BCustDF$Location <- as.factor(BCustDF$Location)
BCustDF$Gender <- as.factor(BCustDF$Gender)
BCustDF$Age <- as.numeric(BCustDF$Age)
BCustDF$Tenure <- as.numeric(BCustDF$Tenure)
BCustDF$Balance <- as.numeric(BCustDF$Balance)
BCustDF$NumOfProducts <- as.numeric(BCustDF$NumOfProducts)
BCustDF$HasCrCard <- as.numeric(BCustDF$HasCrCard)
BCustDF$IsActiveMember<- as.numeric(BCustDF$IsActiveMember)
BCustDF$EstimatedSalary <- as.numeric(BCustDF$EstimatedSalary)
BCustDF$Exited <- as.factor(BCustDF$Exited)
#Checking dataframe structure again after conversion
str(BCustDF)
library(caTools)
#Splitting data into Training and Test
set.seed(1000)
split = sample.split(BCustDF$Exited, SplitRatio = 0.8)
training_set = subset(BCustDF, split == TRUE)
test_set = subset(BCustDF, split == FALSE)
View(training_set)
View(test_set)
#Applying Decision Tree Model
library(rpart)
install.packages("rpart.plot")
library(rpart.plot)
decision_tree_model<-rpart(Exited~CreditScore + Location + Gender + Age + Tenure + Balance + NumOfProducts + HasCrCard + IsActiveMember + EstimatedSalary,data=training_set,method="class",cp=0.0001,minbucket = 25)
rpart.plot(decision_tree_model,type=5)
printcp(decision_tree_model)
plotcp(decision_tree_model)
prp(decision_tree_model)
dtree.prune<- prune(decision_tree_model, cp=0.0004)
dtree.prune
rpart.plot(dtree.prune,type = 5,extra=101)
plotcp(dtree.prune)
dt_predic_class = predict(dtree.prune,test_set,type="class")
#Plotting ROC Curve
library(ROCR)
library(caTools)
install.packages("rsq")
library(rsq)
dt_predic_class <- as.numeric(dt_predic_class)
predt <- prediction(dt_predic_class,test_set$Exited)
ROCperflr <- performance(predt,measure="tpr",x.measure = "fpr")
plot(ROCperflr, colorsize = TRUE, print.cutoffs.at=seq(0,1,by=0.1),text.adj=c(-0.2,1.7))
library(caret)
#data.frame(R2 = R2(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), RMSE = RMSE(as.numeric(dt_predic_class),as.numeric(test_set$Exited)), MAE = MAE(as.numeric(dt_predic_class),as.numeric(test_set$Exited)))
class(dt_predic_class)
dt_predic_class <- as.factor(dt_predic_class)
levels(dt_predic_class) <- list("0" = "1", "1" = "2")
conf_mat <- confusionMatrix(as.factor(dt_predic_class),as.factor(test_set$Exited))
conf_mat
model <- "Decision Tree Model"
accuracy <- conf_mat$overall[1]
accuracy_table <- data.frame(model,accuracy)
accuracy_table
install.packages("rsq")
BCustDF1 <- read.csv(file="Bank_CUstomer_Churn_Data.csv")
head(BCustDF1)
summary(BCustDF1)
str(BCustDF1)
sapply(BCustDF1,function(x) sum(is.na(x)))
BCustDF1$RowNumber <- NULL
BCustDF1$Surname <- NULL
summary(BCustDF1)
head(BCustDF1)
#Converting into Factors
BCustDF1$Exited <- as.factor(BCustDF1$Exited)
#BCustDF1$CustomerId <- as.factor(BCustDF1$CustomerId)
BCustDF1$CreditScore <- as.numeric(BCustDF1$CreditScore)
BCustDF1$Location <- as.factor(BCustDF1$Location)
BCustDF1$Gender <- as.factor(BCustDF1$Gender)
BCustDF1$Age <- as.numeric(BCustDF1$Age)
BCustDF1$Tenure <- as.numeric(BCustDF1$Tenure)
BCustDF1$Balance <- as.numeric(BCustDF1$Balance)
BCustDF1$NumOfProducts <- as.numeric(BCustDF1$NumOfProducts)
BCustDF1$HasCrCard <- as.factor(BCustDF1$HasCrCard)
BCustDF1$IsActiveMember<- as.factor(BCustDF1$IsActiveMember)
#BCustDF1$EstimatedSalary <- as.factor(BCustDF1$EstimatedSalary)
library(randomForest)
#drops <- c("reviews_per_month")
#df = listings[ , !(names(listings) %in% drops)]
library(caTools)
set.seed(1000)
split = sample.split(BCustDF1$Exited, SplitRatio = 0.8)
training_set = subset(BCustDF1, split == TRUE)
test_set = subset(BCustDF1, split == FALSE)
View(training_set)
View(test_set)
#RandomForest Model
rf <- randomForest(formula = Exited ~ .,data = training_set,mtry=4, ntree=500, importance=TRUE, do.trace=100)
rf
print(rf)
importance(rf)
plot(rf)
dt_predic = predict(rf,test_set,type="class")
# Model Performance Matrix
data.frame(R2 = R2(as.numeric(dt_predic),as.numeric(test_set$Exited)), RMSE = RMSE(as.numeric(dt_predic),as.numeric(test_set$Exited)), MAE = MAE(as.numeric(dt_predic),as.numeric(test_set$Exited)))
class(dt_predic)
class(test_set$Exited)
#Plotting ROC Curve
#install.packages(("ROCR"))
library(ROCR)
dt_predic <- as.numeric(dt_predic)
predt <- prediction(dt_predic,test_set$Exited)
ROCperflr <- performance(predt,measure="tpr",x.measure = "fpr")
plot(ROCperflr, colorsize = TRUE, print.cutoffs.at=seq(0,1,by=0.2),text.adj=c(-0.2,1.7))
library(caret)
dt_predic<- as.factor(dt_predic)
levels(dt_predic) <- list("0" = "1", "1" = "2")
conf_mat <- confusionMatrix(as.factor(dt_predic),as.factor(test_set$Exited))
conf_mat
model <- "Random Forest Model"
accuracy <- conf_mat$overall[1]
accuracy_table <- data.frame(model,accuracy)
accuracy_table
library(stats)
library(caTools)
library(Amelia)
library(dplyr)
setwd("~/National College of Ireland/Machine Learning Project/Final Datasets/DMML_CA1/IBM Churn Analysis")
IBMDF <- read.csv(file="IBM_HR_Data_new.csv")
head(IBMDF)
str(IBMDF)
summary(IBMDF)
#Print the structure of the dataframe
print(str(IBMDF))
#Checking if there are any null values
sapply(IBMDF,function(x) sum(is.na(x)))
IBMDF_new <- na.omit(IBMDF)
sapply(IBMDF_new,function(x) sum(is.na(x)))
summary(IBMDF_new) #No NULL values here!
#Missing Values vs Observed Values
missmap(IBMDF_new)
# Check for any correlated variables
library(corrplot)
cor <- cor(IBMDF_new[sapply(IBMDF_new,is.numeric)])
corrplot(cor)
cor(cor)
IBMDF_new$DailyRate <- NULL
IBMDF_new$Department <- NULL
IBMDF_new$Education <- NULL
IBMDF_new$EducationField <- NULL
IBMDF_new$EducationCount <- NULL
IBMDF_new$Department <- NULL
IBMDF_new$EmployeeCount <- NULL
IBMDF_new$EmployeeNumber <- NULL
IBMDF_new$StandardHours <- NULL
IBMDF_new$Over18 <- NULL
IBMDF_new$Application.ID <- NULL
IBMDF_new$Employee.Source <- NULL
IBMDF_new$NumCompaniesWorked <- NULL
IBMDF_new$RelationshipSatisfaction <- NULL
IBMDF_new$TrainingTimesLastYear <- NULL
IBMDF_new$PerformanceRating <- NULL
IBMDF_new$PerformanceHike <- NULL
IBMDF_new$JobRole <- NULL
IBMDF_new$JobSatisfaction <- NULL
IBMDF_new$MaritalStatus <- NULL
IBMDF_new$EnvironmentSatisfaction <- NULL
IBMDF_new$YearsWithCurrManager  <- NULL
IBMDF_new$Employee.Source <- NULL
str(IBMDF_new)
summary(IBMDF_new)
install.packages("ggplot2")
library(ggplot2)
#Business Travel against Attrition
ggplot(IBMDF_new,
aes(x= BusinessTravel,  group=Attrition)) +
geom_bar(aes(y = ..prop.., fill = factor(..x..)),
stat="count",
alpha = 0.7) +
geom_text(aes(label = scales::percent(..prop..), y = ..prop.. ),
stat= "count",
vjust = -.5) +
labs(y = "Percentage", fill="Business Travel") +
facet_grid(~Attrition) +
scale_y_continuous() +
scale_fill_manual(values = c("purple", "blue","red","purple")) +
theme(legend.position = "none", plot.title = element_text(hjust = 0.5)) +
ggtitle("Attrition") +
labs(x = "Business Travel")
unique(IBMDF_new$OverTime )
#OverTime Against Attrition
ggplot(IBMDF_new,
aes(x = OverTime, group = Attrition)) +
geom_bar(aes(y = ..prop.., fill = factor(..x..)),
stat="count",
alpha = 0.7) +
geom_text(aes(label = scales::percent(..prop..), y = ..prop.. ),
stat= "count",
vjust = -.5) +
labs(y = "Percentage", fill= "OverTime") +
facet_grid(~Attrition) +
scale_fill_manual(values = c("Blue","red","orange","blue")) +
theme(legend.position = "none", plot.title = element_text(hjust = 0.5)) +
ggtitle("Attrition")
par(mfrow=c(1,3))
hist(IBMDF_new$Age, main = "Age", xlab = "Age", ylab = "Count", col = "black", )
hist(IBMDF_new$TotalWorkingYears, main = "Total Working Years", xlab = "Total Working Years", ylab = "Count", col = "black")
hist(IBMDF_new$YearsAtCompany, main = "Years AT Company", xlab = "Years At Company", ylab = "Count", col = "black")
#Need to remove Outliers
par(mfrow=c(3,3))
boxplot(IBMDF_new$Age,xlab = "Age")
boxplot(IBMDF_new$JobInvolvement,xlab = "Job Involvement")
#boxplot(IBMDF_new$JobLevel,ylab = "Job Level")
boxplot(IBMDF_new$StockOptionLevel, xlab = "StockOptionLevel")
boxplot(IBMDF_new$TotalWorkingYears, xlab = "Total Working Years")
boxplot(IBMDF_new$YearsAtCompany, xlab = "Years At Company")
boxplot(IBMDF_new$Gender, xlab = "Gender")
boxplot(IBMDF_new$JobInvolvement, xlab = "Job Involvement")
boxplot(IBMDF_new$JobLevel, xlab = "Job Level")
boxplot(IBMDF_new$WorkLifeBalance, xlab = "WorkLifeBalance")
boxplot(IBMDF_new$YearsAtCompany, xlab = "Years At Company")
#Apply COnditions to Remove Outliers
library(dplyr)
IBMDF_new = subset(IBMDF_new, Age<60 & YearsAtCompany<19 & JobInvolvement<50 & StockOptionLevel<2.5 & TotalWorkingYears<18 & YearsAtCompany<14 & JobLevel<3)
str(IBMDF_new)
#Check to confirm if outliers are removed
boxplot(IBMDF_new$Age,ylab = "Age")
boxplot(IBMDF_new$JobInvolvement,ylab = "Job Involvement")
boxplot(IBMDF_new$JobLevel,ylab = "Job Level")
boxplot(IBMDF_new$StockOptionLevel, ylab = "StockOptionLevel")
boxplot(IBMDF_new$TotalWorkingYears, ylab = "Total Working Years")
boxplot(IBMDF_new$Gender, ylab = "Gender")
boxplot(IBMDF_new$WorkLifeBalance, ylab = "WorkLifeBalance")
boxplot(IBMDF_new$YearsAtCompany, ylab = "Years At Company")
#Creating Dummy Variable for Attrition Column
IBMDF_new$Attrition <- ifelse(IBMDF_new$Attrition == "Voluntary Resignation",1,0)
head(IBMDF_new)
#Transformation of Attrition
IBMDF_new$Attrition <- as.factor(IBMDF_new$Attrition)
library(caTools)
set.seed(1000)
split = sample.split(IBMDF_new$Attrition, SplitRatio = 0.8)
training_set = subset(IBMDF_new, split == TRUE)
test_set = subset(IBMDF_new, split == FALSE)
View(training_set)
View(test_set)
#Final Model - Logistic Regression
#mod<-glm(Attrition ~.,data = training_set,family = "binomial")
#summary(mod)
str(IBMDF_new)
mod1<-glm(Attrition ~ Age + Gender + JobInvolvement + HourlyRate + JobLevel + StockOptionLevel + TotalWorkingYears + YearsAtCompany + BusinessTravel + WorkLifeBalance,data = training_set,family = "binomial")
summary(mod1)
data_pred <- predict(mod1, type="response",newdata = test_set)
summary(data_pred)
#Plotting ROC Curve
install.packages(("ROCR"))
library(ROCR)
predt <- prediction(data_pred, test_set$Attrition)
ROCperflr <- performance(predt,"tpr","fpr")
plot(ROCperflr, colorsize = TRUE, print.cutoffs.at=seq(0,1,by=0.1))
data_pred <- ifelse(data_pred>=0.5,"1","0")
test_set$Attrition <- as.factor(test_set$Attrition)
install.packages("caret")
library(caret)
#Confusion Matrix
conf_mat <- confusionMatrix(as.factor(data_pred), test_set$Attrition, positive = "1")
conf_mat
#Getting Accuracy
accuracy <- conf_mat$overall[1]
model <- "Logistic Regression"
Accuracy_table <- data.frame(model,accuracy)
Accuracy_table
install.packages("ggplot2")
install.packages("caret")
install.packages("ggplot2")
#Naive Bayes Model
library(caret)
library(irr)
library(rpart)
library(tidyverse)
library(e1071)
#setwd("~/National College of Ireland/Machine Learning Project/Final Datasets/Jupyter FIles/IBM Churn Analysis")
IBMDF1 <- read.csv(file="IBM_HR_Data_new.csv")
head(IBMDF1)
#Print the structure of the dataframe
print(str(IBMDF1))
#Checking if there are any null values
sapply(IBMDF1,function(x) sum(is.na(x)))
IBMDF1_new <- na.omit(IBMDF1)
sapply(IBMDF1_new,function(x) sum(is.na(x)))
summary(IBMDF1_new)
IBMDF1_new$DailyRate <- NULL
IBMDF1_new$Department <- NULL
IBMDF1_new$Education <- NULL
IBMDF1_new$EducationField <- NULL
IBMDF1_new$EducationCount <- NULL
IBMDF1_new$Department <- NULL
IBMDF1_new$EmployeeCount <- NULL
IBMDF1_new$EmployeeNumber <- NULL
IBMDF1_new$StandardHours <- NULL
IBMDF1_new$Over18 <- NULL
IBMDF1_new$Application.ID <- NULL
IBMDF1_new$Employee.Source <- NULL
IBMDF1_new$NumCompaniesWorked <- NULL
IBMDF1_new$RelationshipSatisfaction <- NULL
IBMDF1_new$TrainingTimesLastYear <- NULL
IBMDF1_new$PerformanceRating <- NULL
IBMDF1_new$PerformanceHike <- NULL
IBMDF1_new$JobRole <- NULL
IBMDF1_new$JobSatisfaction <- NULL
IBMDF1_new$MaritalStatus <- NULL
IBMDF1_new$EnvironmentSatisfaction <- NULL
IBMDF1_new$YearsWithCurrManager  <- NULL
IBMDF1_new$Employee.Source <- NULL
summary(IBMDF1_new)
#Need to remove Outliers
boxplot(IBMDF1_new$Age,ylab = "Age")
boxplot(IBMDF1_new$JobInvolvement,ylab = "Job Involvement")
boxplot(IBMDF1_new$JobLevel,ylab = "Job Level")
boxplot(IBMDF1_new$StockOptionLevel, ylab = "StockOptionLevel")
boxplot(IBMDF1_new$TotalWorkingYears, ylab = "Total Working Years")
boxplot(IBMDF1_new$YearsAtCompany, ylab = "Years At Company")
boxplot(IBMDF1_new$Gender, ylab = "Gender")
boxplot(IBMDF1_new$JobInvolvement, ylab = "Job Involvement")
boxplot(IBMDF1_new$JobLevel, ylab = "Job Level")
boxplot(IBMDF1_new$WorkLifeBalance, ylab = "WorkLifeBalance")
boxplot(IBMDF1_new$YearsAtCompany, ylab = "Years At Company")
#Apply COnditions to Remove Outliers
library(dplyr)
IBMDF1_new = subset(IBMDF1_new, as.numeric(Age)<60 & as.numeric(YearsAtCompany)<19 & as.numeric(JobInvolvement)<50 & as.numeric(StockOptionLevel)<2.5 & as.numeric(TotalWorkingYears)<18 & as.numeric(YearsAtCompany)<14 & as.numeric(JobLevel)<3)
str(IBMDF1_new)
#Check to confirm if outliers are removed
boxplot(IBMDF1_new$Age,ylab = "Age")
boxplot(IBMDF1_new$JobInvolvement,ylab = "Job Involvement")
boxplot(IBMDF1_new$JobLevel,ylab = "Job Level")
boxplot(IBMDF1_new$StockOptionLevel, ylab = "StockOptionLevel")
boxplot(IBMDF1_new$TotalWorkingYears, ylab = "Total Working Years")
boxplot(IBMDF1_new$Gender, ylab = "Gender")
boxplot(IBMDF1_new$WorkLifeBalance, ylab = "WorkLifeBalance")
boxplot(IBMDF1_new$YearsAtCompany, ylab = "Years At Company")
IBMDF1_new$Age <- as.factor(IBMDF1_new$Age)
IBMDF1_new$BusinessTravel <- as.factor(IBMDF1_new$BusinessTravel)
IBMDF1_new$Gender<- as.factor(IBMDF1_new$Gender)
IBMDF1_new$HourlyRate <- as.factor(IBMDF1_new$HourlyRate)
IBMDF1_new$JobLevel <- as.factor(IBMDF1_new$JobLevel)
IBMDF1_new$StockOptionLevel <- as.factor(IBMDF1_new$StockOptionLevel)
IBMDF1_new$TotalWorkingYears <- as.factor(IBMDF1_new$TotalWorkingYears)
IBMDF1_new$WorkLifeBalance <- as.factor(IBMDF1_new$WorkLifeBalance)
IBMDF1_new$YearsAtCompany <- as.factor(IBMDF1_new$YearsAtCompany)
missmap(IBMDF_new)
IBMDF1_new$Attrition <- ifelse(IBMDF1_new$Attrition == "Voluntary Resignation",1,0)
IBMDF1_new$Attrition <- as.factor(IBMDF1_new$Attrition)
str(IBMDF1_new)
# Partition of Data
library(caTools)
set.seed(1000)
split = sample.split(IBMDF1_new$Attrition, SplitRatio = 0.8)
training_set = subset(IBMDF1_new, split == TRUE)
test_set = subset(IBMDF1_new, split == FALSE)
View(training_set)
View(test_set)
nbmodel<-naiveBayes(Attrition~ Age + Gender + HourlyRate + MonthlyIncome + JobLevel + JobInvolvement + StockOptionLevel + TotalWorkingYears + YearsAtCompany + BusinessTravel + WorkLifeBalance,data = training_set)
nbmodel
#Prediction of Output Variable
pred_nb <- as.numeric(pred_nb)
pred_nb <- ifelse(pred_nb>=0.5,"1","0")
pred_nb <- as.numeric(pred_nb)
pred_nb <- predict(nbmodel, newdata = test_set)
class(pred_nb)
test_set$Attrition
#Plotting ROC Curve
#install.packages(("ROCR"))
library(ROCR)
pred_nb <- as.numeric(pred_nb)
predt <- prediction(pred_nb,test_set$Attrition)
ROCperflr <- performance(predt,measure="tpr",x.measure = "fpr")
plot(ROCperflr, colorsize = TRUE, print.cutoffs.at=seq(0,1,by=0.2),text.adj=c(-0.2,1.7))
table(test_set$Attrition,pred_nb)
#Confusion Matrix
library(caret)
pred_nb <- as.factor(pred_nb)
levels(pred_nb) <- list("0" = "1", "1" = "2")
str(pred_nb)
conf_mat <- confusionMatrix(as.factor(pred_nb),as.factor(test_set$Attrition))
conf_mat
model <- "Naive Bayes Model"
accuracy <- conf_mat$overall[1]
accuracy_table <- data.frame(model,accuracy)
accuracy_table
